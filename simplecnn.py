# -*- coding: utf-8 -*-
"""simpleCNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nL_wmRjzL2bAEaBjVKbYmbFDlAT1GGeS
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd

# --- Configuration ---
torch.manual_seed(42)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
RESULTS_DIR = "cnn_experiment_results_full"
os.makedirs(RESULTS_DIR, exist_ok=True)

# --- Data Loading (MNIST) ---
transform = transforms.Compose([transforms.ToTensor()])
train_dataset = torchvision.datasets.MNIST(root="./data", train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.MNIST(root="./data", train=False, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)

# --- CNN Model ---
class SimpleCNN(nn.Module):
    def __init__(self, activation="relu"):
        super(SimpleCNN, self).__init__()
        activations = {
            "sigmoid": nn.Sigmoid(),
            "relu": nn.ReLU(),
            "leakyrelu": nn.LeakyReLU(0.01),
            "gelu": nn.GELU(),
            "silu": nn.SiLU(),
        }
        act = activations[activation.lower()]

        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),
            act,
            nn.MaxPool2d(2, 2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            act,
            nn.MaxPool2d(2, 2)
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 7 * 7, 128),
            act,
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

# --- Training & Evaluation ---
def train_one_epoch_grad(model, loader, optimizer, loss_fn):
    model.train()
    total_loss, total_correct = 0, 0
    grad_norms = []

    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = loss_fn(out, y)
        loss.backward()

        total_norm = 0.0
        for p in model.parameters():
            if p.grad is not None:
                param_norm = p.grad.data.norm(2).item()
                total_norm += param_norm ** 2
        total_norm = total_norm ** 0.5
        grad_norms.append(total_norm)

        optimizer.step()
        total_loss += loss.item() * x.size(0)
        total_correct += (out.argmax(1) == y).sum().item()

    avg_grad_norm = sum(grad_norms) / len(grad_norms)
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset), avg_grad_norm


def evaluate(model, loader, loss_fn):
    model.eval()
    total_loss, total_correct = 0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            loss = loss_fn(out, y)
            total_loss += loss.item() * x.size(0)
            total_correct += (out.argmax(1) == y).sum().item()
    return total_loss / len(loader.dataset), total_correct / len(loader.dataset)


# --- Experiment Runner ---
def run_experiment(activation="relu", optimizer_name="sgdm", epochs=5, lr=0.001):
    model = SimpleCNN(activation).to(device)
    loss_fn = nn.CrossEntropyLoss()

    if optimizer_name == "sgdm":
        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)
    elif optimizer_name == "adam":
        optimizer = optim.Adam(model.parameters(), lr=lr)
    elif optimizer_name == "adamw":
        optimizer = optim.AdamW(model.parameters(), lr=lr)
    elif optimizer_name == "rmsprop":
        optimizer = optim.RMSprop(model.parameters(), lr=lr)

    train_losses, val_losses, train_accs, val_accs, grad_norms = [], [], [], [], []

    for epoch in range(epochs):
        tl, ta, gn = train_one_epoch_grad(model, train_loader, optimizer, loss_fn)
        vl, va = evaluate(model, test_loader, loss_fn)
        train_losses.append(tl)
        val_losses.append(vl)
        train_accs.append(ta)
        val_accs.append(va)
        grad_norms.append(gn)

        print(f"[{activation}+{optimizer_name}] Epoch {epoch+1}/{epochs} | Val Acc: {va:.4f} | GradNorm: {gn:.4f}")

    # Save results to CSV
    df = pd.DataFrame({
        "Epoch": range(1, epochs + 1),
        "Train_Loss": train_losses,
        "Val_Loss": val_losses,
        "Train_Acc": train_accs,
        "Val_Acc": val_accs,
        "Grad_Norm": grad_norms
    })
    csv_path = os.path.join(RESULTS_DIR, f"{activation}_{optimizer_name}.csv")
    df.to_csv(csv_path, index=False)

    return train_losses, val_losses, train_accs, val_accs, grad_norms


# --- Run Experiments ---
ACTIVATIONS = ["sigmoid", "relu", "leakyrelu", "gelu", "silu"]
OPTIMIZERS = ["sgdm", "adam", "adamw", "rmsprop"]
EPOCHS = 5
results = {}

for act in ACTIVATIONS:
    for opt in OPTIMIZERS:
        lr = 0.01 if opt == "sgdm" else 0.001
        print(f"\nRunning {act} + {opt} (lr={lr})")
        train_l, val_l, train_a, val_a, grad_n = run_experiment(act, opt, epochs=EPOCHS, lr=lr)
        results[f"{act}_{opt}"] = (train_l, val_l, train_a, val_a, grad_n)


# --- Visualization Section ---
for act in ACTIVATIONS:
    plt.figure(figsize=(10, 6))
    for opt in OPTIMIZERS:
        _, val_accs, _, _, _ = results[f"{act}_{opt}"]
        plt.plot(range(1, EPOCHS + 1), val_accs, marker='o', label=opt.upper())
    plt.xlabel("Epochs")
    plt.ylabel("Validation Accuracy")
    plt.title(f"{act.upper()} Activation – Validation Accuracy across Optimizers")
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(RESULTS_DIR, f"{act}_val_acc.png"))
    plt.close()

for opt in OPTIMIZERS:
    plt.figure(figsize=(10, 6))
    for act in ACTIVATIONS:
        _, _, _, val_accs, _ = results[f"{act}_{opt}"]
        plt.plot(range(1, EPOCHS + 1), val_accs, marker='o', label=act.upper())
    plt.xlabel("Epochs")
    plt.ylabel("Validation Accuracy")
    plt.title(f"{opt.upper()} Optimizer – Validation Accuracy across Activations")
    plt.legend()
    plt.grid(True)
    plt.savefig(os.path.join(RESULTS_DIR, f"{opt}_val_acc.png"))
    plt.close()

print("\n✅ All experiments complete. CSVs and plots saved in:", RESULTS_DIR)